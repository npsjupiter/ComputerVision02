{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qstumIY8YC8v"
   },
   "source": [
    "# Image Classification of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxcWOCZgYC8x"
   },
   "source": [
    "### 1.0 Import packages and libraries\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qjjbDNm2YC8z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import keras\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# from skimage import feature, data, io, measure\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWZ1h6ASYC9Q"
   },
   "source": [
    "### 2 Global Variables \n",
    "Enter the batch size for training, testing and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QP2O0tA5YC9R"
   },
   "outputs": [],
   "source": [
    "batch_size_train = 20\n",
    "batch_size_val = 10\n",
    "batch_size_test = 25\n",
    "num_classes= 5\n",
    "intereseted_folder='Documents'\n",
    "STANDARD_SIZE=(224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6w6HRzPYC9X"
   },
   "source": [
    "# 3. Classification\n",
    "\n",
    "## 3.1 Create the Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2VDfSdeYYC9Z"
   },
   "outputs": [],
   "source": [
    "#Converting Data Format according to the backend used by Keras\n",
    "\n",
    "classes_required = ['Cheque', 'Documents', 'Driving_License', 'Pancard', 'Passport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NeToUoplYC9e"
   },
   "outputs": [],
   "source": [
    "datagen=keras.preprocessing.image.ImageDataGenerator(data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "crXYvXVEYC9l",
    "outputId": "7c02e98c-087d-41ef-a592-7983fd938808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input the Training Data\n",
    "\n",
    "train_path = r'C:\\Users\\ark11\\Desktop\\Ark Teaching\\Alabs\\DL\\Class 6-7 Files\\CNN\\Image Classification Case Study-2 (Using Transfer Learning)\\Data\\Train_Data'\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_train)\n",
    "type(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "h6ZgVPePZU6J",
    "outputId": "73ca6da1-ef4c-484e-c654-c00e467afe01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "C3-cqvV1YC9t",
    "outputId": "412d0d49-e558-47e0-fd8c-88b12b023f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Input the Validation Data\n",
    "val_path = r'C:\\Users\\ark11\\Desktop\\Ark Teaching\\Alabs\\DL\\Class 6-7 Files\\CNN\\Image Classification Case Study-2 (Using Transfer Learning)\\Data\\Val_Data'\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "99WuQFYUYC91",
    "outputId": "f6bbf6b5-23d3-4102-d6b4-4dc6ceb8178b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Input the Test Data\n",
    "test_path = r'C:\\Users\\ark11\\Desktop\\Ark Teaching\\Alabs\\DL\\Class 6-7 Files\\CNN\\Image Classification Case Study-2 (Using Transfer Learning)\\Data\\Test_Data'\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IkZdMh4lYC97"
   },
   "outputs": [],
   "source": [
    "# next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1l_qFRvGYC-D"
   },
   "outputs": [],
   "source": [
    "train_imgs, train_labels = next(train_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjzwAsC4YC-J"
   },
   "outputs": [],
   "source": [
    "# train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQv7i-skYC-Q"
   },
   "outputs": [],
   "source": [
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b_PLmrGYC-Y"
   },
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qz7uSz5GYC-e"
   },
   "outputs": [],
   "source": [
    "# test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebjPSzSjYC-h"
   },
   "outputs": [],
   "source": [
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIOefKvZYC-m"
   },
   "outputs": [],
   "source": [
    "# y_test= [ np.where(r==1)[0][0] for r in test_labels ]\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is9SnH9cYC-p"
   },
   "source": [
    "## 3.2 Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "DUR5kpPuYC-q",
    "outputId": "07cef9c6-f27f-4440-879d-d60b5aae538e"
   },
   "outputs": [],
   "source": [
    "model = keras.applications.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9dNJY6gGYC-t",
    "outputId": "ff9c5187-1b64-4f8c-eede-5cc6525d6c31"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fcsLbSkCYC-w",
    "outputId": "02bd6ebd-0c35-4741-f42f-4282dbb37106"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "spp8MUuiYC-1",
    "outputId": "d4fc46b5-e840-47a1-9b7f-ece744382271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      " 30892032/553467096 [>.............................] - ETA: 1:18:08"
     ]
    }
   ],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LPUrxuetYC-5",
    "outputId": "1d77cc7d-b747-40cb-e356-5654bcf98fdc"
   },
   "outputs": [],
   "source": [
    "type(vgg16_model) #This is a Keras Functional API need to convert to sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "QQlnTxUxYC-8",
    "outputId": "d686a0ab-532b-43d6-bd76-029f16635a17"
   },
   "outputs": [],
   "source": [
    "vgg16_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2g-FsHqTYC-_"
   },
   "outputs": [],
   "source": [
    "model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "id": "j_Gv_1TDYC_D",
    "outputId": "5c2e1231-7daf-4b4b-c993-54fe10e8bf3e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvT31C1xYC_J"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2W6diuhYC_N"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='softmax')) # Add the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "obHwpD8xYC_T",
    "outputId": "dee86f89-91af-46e0-e121-565945d56d8e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpnU9IG7YC_Y"
   },
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "model.compile(Adam(lr=.00015), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz8obcMfYC_b"
   },
   "source": [
    "## 3.3 Train the Model\n",
    "\n",
    "The model will take about 30-45 minutes to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "VUahL1EoYC_b",
    "outputId": "69046bc2-071a-4555-81d1-6c022edcbc53"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=20, \n",
    "                    validation_data=val_batches, validation_steps=20, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YpWhu40-YC_e",
    "outputId": "2ef1e309-f825-409a-b46c-d3f113d8eabe"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZBd8QLDYC_h"
   },
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')\n",
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "VYpTfvnaYC_n",
    "outputId": "e86bc1fa-2e49-475a-b8bb-adbf3fe3175a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7C3llT1UYC_r",
    "outputId": "25caa892-745b-41ac-ca5e-1ea81b213a8b"
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqZwUfvOYC_u"
   },
   "source": [
    "## 3.4 Test the Model with External Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VB75yCdYC_u"
   },
   "outputs": [],
   "source": [
    "zip_ref = 'C:/Users/HP/Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFEkPKVQYC_x"
   },
   "outputs": [],
   "source": [
    "paths = [zip_ref+\"/cheque copy 2.jpg\", zip_ref+\"/cheque copy 2.jpg\",zip_ref+\"/cheque copy 2.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "cCvFHZ03YC_z",
    "outputId": "b6f23ee8-ffe2-4063-d35f-20f18e862fba"
   },
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "pRcKlIEWYC_4",
    "outputId": "836fb68d-d650-44b4-d58f-40722e66ac8a"
   },
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "def convert_to_image(X):\n",
    "    '''Function to convert all Input Images to the STANDARD_SIZE and create Training Dataset\n",
    "    '''\n",
    "    for f in paths:\n",
    "        #fobj=get_file(f)\n",
    "        #print(type(fobj))predictions= model.predict(X_test)\n",
    "        if os.path.isdir(f):\n",
    "            continue\n",
    "        img= PIL.Image.open(f)\n",
    "        img = img.resize(STANDARD_SIZE)\n",
    "        img=np.array(img)\n",
    "        X.append(img)\n",
    "        #print(X_train)\n",
    "    #print(len(X_train))\n",
    "    return X\n",
    "X_test=np.array(convert_to_image(X_test))\n",
    "datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ol-WqDGRYC_8"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Arav5ES0YDAA"
   },
   "outputs": [],
   "source": [
    "predictions= model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObA-bxokYDAD"
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(len(predictions)):\n",
    "    y_pred.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKySe3M5YDAJ"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sju-k3bQYDAR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrOAWmQRYDAW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Nh4yIzHYDAb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN- Transfer learning -Image Classification of Documents Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
